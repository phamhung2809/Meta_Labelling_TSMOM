{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vGz62fAE6zzH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\NPW\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\NPW\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\NPW\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np ## bug\n",
        "import gpflow\n",
        "import tensorflow as tf\n",
        "import datetime as dt\n",
        "from gpflow.kernels import ChangePoints, Matern32\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from tensorflow_probability import bijectors as tfb\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "Kernel = gpflow.kernels.base.Kernel\n",
        "MAX_ITERATIONS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYx02MPe_nV_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"all: initial; font-family: 'Lexend', sans-serif; display: flex; flex-wrap: wrap; max-width: 100%; margin: 12px 0; border-radius: 10px; overflow: hidden; background: #ffffff; box-shadow: 0 4px 12px rgba(0,0,0,0.08); color: #333;\">\n",
              "  <div style=\"flex: 1; padding: 12px 16px; display: flex; flex-direction: column; justify-content: center;\">\n",
              "    <h2 style=\"margin: 0 0 10px 0; line-height: 1.3; font-size: 18px; font-weight: 700; color: #4CAF50;\">\n",
              "      <span style=\"color: #8C52FF;\">Bi·∫øn D·ªØ Li·ªáu Th√†nh L·ª£i Nhu·∫≠n -</span> Khai gi·∫£ng Python Ch·ª©ng Kho√°n K11\n",
              "    </h2>\n",
              "    <ul style=\"list-style: none; padding-left: 0; margin: 10px 0 12px 0; font-size: 13px; line-height: 1.4;\">\n",
              "      <li style=\"margin-bottom: 6px;\"><strong style=\"color:#8C52FF;\">‚ú® Bao h·ªçc 2 kho√°:</strong> H·ªçc ch√≠nh th·ª©c t·ª´ 15/6/2025 v√† h·ªçc qua video Kho√° 10!</li>\n",
              "      <li style=\"margin-bottom: 6px;\"><strong style=\"color:#8C52FF;\">üöÄ K·ªπ nƒÉng th·ª±c chi·∫øn:</strong> T·∫°o bot ch·ª©ng kho√°n t·ª´ con s·ªë 0</li>\n",
              "      <li style=\"margin-bottom: 6px;\"><strong style=\"color:#8C52FF;\">üíØ C·ªông ƒë·ªìng:</strong> K·∫øt n·ªëi 100+ nh√† ƒë·∫ßu t∆∞ & chuy√™n gia</li>\n",
              "    </ul>\n",
              "    <div style=\"text-align: center;\">\n",
              "      <a href=\"https://vnstocks.com/lp-khoa-hoc-python-chung-khoan\" style=\"display: inline-block; background-color: #4CAF50; color: #fff; padding: 6px 16px; text-decoration: none; font-size: 13px; border-radius: 20px; font-weight: 600;\">\n",
              "        ƒêƒÉng k√Ω <span style=\"font-size: 13px;\">‚ûú</span>\n",
              "      </a>\n",
              "    </div>\n",
              "  </div>\n",
              "  <a href=\"https://vnstocks.com/lp-khoa-hoc-python-chung-khoan\" style=\"flex: 1; min-width: 180px; max-width: 45%;\">\n",
              "    <img src=\"https://vnstocks.com/images/cta-python-chung-khoan-k11.jpg\" alt=\"Kh√≥a h·ªçc Python Ch·ª©ng kho√°n\" style=\"width: 100%; height: 100%; max-height: 250px; object-fit: cover; display: block;\">\n",
              "  </a>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Phi√™n b·∫£n Vnstock 3.2.6 ƒë√£ c√≥ m·∫∑t, vui l√≤ng c·∫≠p nh·∫≠t v·ªõi c√¢u l·ªánh : `pip install vnstock --upgrade`.\n",
              "L·ªãch s·ª≠ phi√™n b·∫£n: https://vnstocks.com/docs/tai-lieu/lich-su-phien-ban\n",
              "Phi√™n b·∫£n hi·ªán t·∫°i 3.2.3"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Phi√™n b·∫£n Vnai 2.0.4 ƒë√£ c√≥ m·∫∑t, vui l√≤ng c·∫≠p nh·∫≠t v·ªõi c√¢u l·ªánh : `pip install vnai --upgrade`.\n",
              "L·ªãch s·ª≠ phi√™n b·∫£n: https://pypi.org/project/vnai/#history\n",
              "Phi√™n b·∫£n hi·ªán t·∫°i 2.0.2"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from vnstock import Vnstock\n",
        "def VN_Stock_close_data(start_time, end_time, list_choice = 'VN30', interval = '1D'):\n",
        "    \"\"\"\n",
        "    function ƒë·ªÉ fetch data t·ª´ vnstock v·ªÅ, vnindex30\n",
        "    \"\"\"\n",
        "    stock = Vnstock().stock(symbol='ACB', source='VCI')\n",
        "    stock_list = stock.listing.symbols_by_group(list_choice)\n",
        "    futures = pd.DataFrame()\n",
        "\n",
        "    for stock_id in stock_list:\n",
        "        try:\n",
        "            stock = Vnstock().stock(symbol= stock_id , source='VCI')\n",
        "            df = stock.quote.history(start= start_time, end= end_time, interval= interval)\n",
        "            df = df.set_index('time')\n",
        "            df = pd.DataFrame(df['close'])\n",
        "            df.columns = [stock_id]\n",
        "            df.index = df.index.date\n",
        "            futures = pd.concat([futures,df],axis = 1, join = 'outer').sort_index()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if interval != '1D':\n",
        "      futures['Date']= pd.to_datetime(futures.index, format='%Y-%m-%d')\n",
        "    else:\n",
        "      futures['Date'] = pd.to_datetime(futures.index, format='%Y-%m-%d %H:%M:%S')\n",
        "    futures.set_index('Date', inplace=True)\n",
        "\n",
        "    return futures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "R3ud060a_p10",
        "outputId": "d1ad4477-3f87-423b-bbc9-cd1af4acc9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ daily return with null dropped: \n",
            " Date\n",
            "2018-01-03   -0.002937\n",
            "2018-01-04    0.002946\n",
            "2018-01-05    0.000000\n",
            "2018-01-08    0.033774\n",
            "2018-01-09    0.004261\n",
            "                ...   \n",
            "2025-05-19   -0.001881\n",
            "2025-05-20    0.008011\n",
            "2025-05-21    0.001870\n",
            "2025-05-22   -0.003733\n",
            "2025-05-23    0.011710\n",
            "Name: ACB, Length: 1842, dtype: float64\n",
            "‚úÖ daily return as array: [-0.00293686  0.00294551  0.         ...  0.00187003 -0.00373308\n",
            "  0.0117096 ]\n",
            "daily return of ACB as dataframe: \n",
            "             daily_return\n",
            "Date                    \n",
            "2018-01-03     -0.002937\n",
            "2018-01-04      0.002946\n",
            "2018-01-05      0.000000\n",
            "2018-01-08      0.033774\n",
            "2018-01-09      0.004261\n",
            "...                  ...\n",
            "2025-05-19     -0.001881\n",
            "2025-05-20      0.008011\n",
            "2025-05-21      0.001870\n",
            "2025-05-22     -0.003733\n",
            "2025-05-23      0.011710\n",
            "\n",
            "[1842 rows x 1 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n"
          ]
        }
      ],
      "source": [
        "df = VN_Stock_close_data(\n",
        "    start_time=\"2017-12-31\",\n",
        "    end_time= \"2025-05-25\",\n",
        ")\n",
        "data = df['ACB']\n",
        "# data.head()\n",
        "daily_return = data.pct_change().dropna()\n",
        "print(f\"‚úÖ daily return with null dropped: \\n {daily_return}\")\n",
        "print(f\"‚úÖ daily return as array: {daily_return.values}\")\n",
        "daily_return_df = daily_return.to_frame(name = \"daily_return\")\n",
        "print(f\"daily return of ACB as dataframe: \\n {daily_return_df}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pfxm6mS2JGAq"
      },
      "outputs": [],
      "source": [
        "# import yfinance as yf\n",
        "# ticker = \"AAPL\"\n",
        "# start_date = \"2017-12-31\"\n",
        "# end_date   = \"2025-05-25\"\n",
        "\n",
        "# # 2. Download d·ªØ li·ªáu OHLC (·ªü ƒë√¢y ch√∫ng ta ch·ªâ c·∫ßn 'Close')\n",
        "# df_raw = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\",\n",
        "#                      multi_level_index=False)\n",
        "\n",
        "# # df_raw s·∫Ω c√≥ index l√† datetime, v√† c√≥ c·ªôt \"Close\"\n",
        "# # 3. T√≠nh daily return: (Close_t / Close_{t-1} - 1)\n",
        "# df_returns = df_raw[[\"Close\"]].pct_change() \\\n",
        "#                        .dropna() \\\n",
        "#                        .rename(columns={\"Close\": \"daily_return\"})\n",
        "\n",
        "# # 4. ƒê·∫∑t l·∫°i t√™n index th√†nh 'Date' (m·∫∑c ƒë·ªãnh df_raw.index ƒë√£ l√† datetime index)\n",
        "# print(f\"\\n {type(df_returns)}\")\n",
        "# df_returns.index.name = \"Date\"\n",
        "# print(f\"daily return of {ticker}:\\n {df_returns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NFAMrqSo6_4J"
      },
      "outputs": [],
      "source": [
        "## module service\n",
        "class ChangePointDetection(ChangePoints):\n",
        "    def __init__(\n",
        "            self,\n",
        "            kernels: Tuple[Kernel, Kernel],\n",
        "            location: float,\n",
        "            interval: Tuple[float, float],\n",
        "            steepness: float = 1.0,\n",
        "            name: Optional[str] = None\n",
        "    ):\n",
        "        if location < interval[0] or location > interval[1]:\n",
        "            raise ValueError(\n",
        "                \"Location {loc} is not in range [{low},{high}]\".format(\n",
        "                    loc=location, low=interval[0], high=interval[1]\n",
        "                )\n",
        "            )\n",
        "        locations = [location]\n",
        "        super().__init__(\n",
        "            kernels = kernels, locations = locations, steepness = steepness, name=name\n",
        "        )\n",
        "\n",
        "        affine = tfb.Shift(tf.cast(interval[0], tf.float64))(\n",
        "            tfb.Scale(tf.cast(interval[1] - interval[0], tf.float64))\n",
        "        )\n",
        "\n",
        "        self.locations = gpflow.Parameter(\n",
        "            locations, transform=tfb.Chain([affine, tfb.Sigmoid()]), dtype = tf.float64\n",
        "        )\n",
        "\n",
        "        def _sigmoids(self, X: tf.Tensor):\n",
        "            locations = tf.reshape(self.locations, (1, 1, -1))\n",
        "            steepness = tf.reshape(self.steepness, (1, 1, -1))\n",
        "            return tf.sigmoid(steepness * (X[:, :, None] - locations))\n",
        "\n",
        "## fit matern kernel - l√† c√°i baseline\n",
        "def fit_matern_kernel(\n",
        "        time_series_data: pd.DataFrame,\n",
        "        variance: float = 1.0,\n",
        "        lengthscale: float = 1.0,\n",
        "        likelihood_variance: float = 1.0\n",
        "):\n",
        "\n",
        "    model = gpflow.models.GPR(\n",
        "        data = (\n",
        "            time_series_data.loc[:, [\"X\"]].to_numpy(),\n",
        "            time_series_data.loc[:, [\"Y\"]].to_numpy()\n",
        "        ),\n",
        "        kernel = Matern32(variance=variance, lengthscales=lengthscale),\n",
        "        noise_variance=likelihood_variance\n",
        "    )\n",
        "\n",
        "    optimizer = gpflow.optimizers.Scipy()\n",
        "    nlml = optimizer.minimize(\n",
        "        model.training_loss, model.trainable_variables, options=dict(maxiter=MAX_ITERATIONS)\n",
        "    ).fun\n",
        "    parameters = {\n",
        "        \"kM_variance\": model.kernel.variance.numpy(),\n",
        "        \"kM_lengthscales\": model.kernel.lengthscales.numpy(),\n",
        "        \"kM_likelihood_variance\": model.likelihood.variance.numpy()\n",
        "    }\n",
        "\n",
        "    return nlml, parameters\n",
        "\n",
        "## fit cp kernel - l√† c√°i improved nh·ªù add cp v√†o?\n",
        "def fit_changepoint_kernel(\n",
        "        time_series_data: pd.DataFrame,\n",
        "        k1_variance: float = 1.0,\n",
        "        k1_lengthscale: float = 1.0,\n",
        "        k2_variance: float = 1.0,\n",
        "        k2_lengthscale: float = 1.0,\n",
        "        kC_likelihood_variance = 1.0,\n",
        "        kC_changepoint_location = None,\n",
        "        kC_steepness = 1.0\n",
        "):\n",
        "    if not kC_changepoint_location:\n",
        "        kC_changepoint_location = (\n",
        "            time_series_data[\"X\"].iloc[0] + time_series_data[\"X\"].iloc[-1]\n",
        "        ) / 2.0\n",
        "\n",
        "    model = gpflow.models.GPR(\n",
        "        data=(\n",
        "            time_series_data.loc[:, [\"X\"]].to_numpy(),\n",
        "            time_series_data.loc[:, [\"Y\"]].to_numpy()\n",
        "        ),\n",
        "        kernel = ChangePointDetection(\n",
        "            [\n",
        "                Matern32(variance=k1_variance, lengthscales=k1_lengthscale),\n",
        "                Matern32(variance=k2_variance, lengthscales=k2_lengthscale)\n",
        "            ],\n",
        "            location=kC_changepoint_location,\n",
        "            interval=(time_series_data[\"X\"].iloc[0], time_series_data[\"X\"].iloc[-1]),\n",
        "            steepness=kC_steepness\n",
        "        )\n",
        "    )\n",
        "    model.likelihood.variance.assign(kC_likelihood_variance)\n",
        "\n",
        "    optimizer = gpflow.optimizers.Scipy()\n",
        "    nlml = optimizer.minimize(\n",
        "        model.training_loss, model.trainable_variables, options=dict(maxiter=MAX_ITERATIONS)\n",
        "    ).fun\n",
        "    changepoint_location = model.kernel.locations[0].numpy()\n",
        "    parameters = {\n",
        "        \"k1_variance\": model.kernel.kernels[0].variance.numpy().flatten()[0],\n",
        "        \"k1_lengthscale\": model.kernel.kernels[0].lengthscales.numpy().flatten()[0],\n",
        "        \"k2_variance\": model.kernel.kernels[1].variance.numpy().flatten()[0],\n",
        "        \"k2_lengthscale\": model.kernel.kernels[1].lengthscales.numpy().flatten()[0],\n",
        "        \"kC_likelihood_variance\": model.likelihood.variance.numpy().flatten()[0],\n",
        "        \"kC_changepoint_location\": changepoint_location,\n",
        "        \"kC_steepness\": model.kernel.steepness.numpy()\n",
        "    }\n",
        "\n",
        "    return changepoint_location, nlml, parameters\n",
        "\n",
        "## t√≠nh severity , l√† c√°i v_t, v√† c√°i cp_location_normalized, l√† c√°i \\gamma_t\n",
        "def changepoint_severity(\n",
        "     kC_nlml: Union[float, List[float]],\n",
        "     kM_nlml: Union[float, List[float]]\n",
        "):\n",
        "    normalized_nlml = kC_nlml - kM_nlml\n",
        "    return 1 - 1 / (np.mean(np.exp(-normalized_nlml)) + 1)\n",
        "def changepoint_loc_and_score(\n",
        "    time_series_data_window: pd.DataFrame,\n",
        "    kM_variance: float = 1.0,\n",
        "    kM_lengthscale: float = 1.0,\n",
        "    kM_likelihood_variance: float = 1.0,\n",
        "    k1_variance: float = None,\n",
        "    k1_lengthscale: float = None,\n",
        "    k2_variance: float = None,\n",
        "    k2_lengthscale: float = None,\n",
        "    kC_likelihood_variance: float = None,\n",
        "    kC_changepoint_location: float = None,\n",
        "    kC_steepness=1.0\n",
        "):\n",
        "    time_series_data = time_series_data_window.copy()\n",
        "    Y_data = time_series_data[[\"Y\"]].values\n",
        "    time_series_data[[\"Y\"]] = StandardScaler().fit(Y_data).transform(Y_data)\n",
        "\n",
        "\n",
        "    if kM_variance == kM_lengthscale == kM_likelihood_variance == 1.0 :\n",
        "        (kM_nlml, kM_params) = fit_matern_kernel(time_series_data)\n",
        "    else:\n",
        "        (kM_nlml, kM_params) = fit_matern_kernel(time_series_data, kM_variance, kM_lengthscale, kM_likelihood_variance)\n",
        "\n",
        "    is_cp_location_default = (\n",
        "        (not kC_changepoint_location)\n",
        "        or kC_changepoint_location < time_series_data[\"X\"].iloc[0]\n",
        "        or kC_changepoint_location > time_series_data[\"X\"].iloc[-1]\n",
        "    )\n",
        "\n",
        "    if is_cp_location_default:\n",
        "        kC_changepoint_location = (\n",
        "            time_series_data[\"X\"].iloc[-1] + time_series_data[\"X\"].iloc[0]\n",
        "        ) / 2.0\n",
        "\n",
        "    if not k1_variance:\n",
        "        k1_variance = kM_params[\"kM_variance\"]\n",
        "\n",
        "    if not k1_lengthscale:\n",
        "        k1_lengthscale = kM_params[\"kM_lengthscales\"]\n",
        "\n",
        "    if not k2_variance:\n",
        "        k2_variance = kM_params[\"kM_variance\"]\n",
        "\n",
        "    if not k2_lengthscale:\n",
        "        k2_lengthscale = kM_params[\"kM_lengthscales\"]\n",
        "\n",
        "    if not kC_likelihood_variance:\n",
        "        kC_likelihood_variance = kM_params[\"kM_likelihood_variance\"]\n",
        "\n",
        "\n",
        "    if (k1_variance == k1_lengthscale == k2_variance == k2_lengthscale == kC_likelihood_variance == kC_steepness == 1.0) and is_cp_location_default:\n",
        "        (changepoint_location, kC_nlml, kC_params) = fit_changepoint_kernel(time_series_data)\n",
        "    else:\n",
        "        (changepoint_location, kC_nlml, kC_params) = fit_changepoint_kernel(\n",
        "            time_series_data,\n",
        "            k1_variance=k1_variance,\n",
        "            k1_lengthscale=k1_lengthscale,\n",
        "            k2_variance=k2_variance,\n",
        "            k2_lengthscale=k2_lengthscale,\n",
        "            kC_likelihood_variance=kC_likelihood_variance,\n",
        "            kC_changepoint_location=kC_changepoint_location,\n",
        "            kC_steepness=kC_steepness,\n",
        "        )\n",
        "\n",
        "    cp_score = changepoint_severity(kC_nlml, kM_nlml)\n",
        "    cp_loc_normalised = (time_series_data[\"X\"].iloc[-1] - changepoint_location) / (\n",
        "        time_series_data[\"X\"].iloc[-1] - time_series_data[\"X\"].iloc[0]\n",
        "    )\n",
        "\n",
        "    return cp_score, changepoint_location, cp_loc_normalised, kM_params, kC_params\n",
        "\n",
        "## run thu·∫≠t to√°n\n",
        "def run_CPD(\n",
        "    time_series_data: pd.DataFrame,\n",
        "    lookback_window_length: int,\n",
        "    start_date: dt.datetime = None,\n",
        "    end_date: dt.datetime = None,\n",
        "    use_kM_hyp_to_initialize_kC=True\n",
        "):\n",
        "    if start_date and end_date:\n",
        "        first_window = time_series_data.loc[:start_date].iloc[\n",
        "             -(lookback_window_length + 1) :, :\n",
        "         ]\n",
        "\n",
        "        # first_window = time_series_data.loc[:start_date].iloc[\n",
        "        #    -(lookback_window_length + 1) :\n",
        "        # ]\n",
        "        remaining_data = time_series_data.loc[start_date:end_date, :]\n",
        "        # remaining_data = time_series_data.loc[start_date:end_date]\n",
        "        if remaining_data.index[0] == start_date:\n",
        "            remaining_data = remaining_data.iloc[1:]\n",
        "        else:\n",
        "            first_window = first_window.iloc[1:]\n",
        "        time_series_data = pd.concat([first_window, remaining_data]).copy()\n",
        "    else:\n",
        "        raise Exception(\"Pass start and end date.\")\n",
        "\n",
        "    time_series_data[\"Date\"] = time_series_data.index\n",
        "    time_series_data = time_series_data.reset_index(drop=True)\n",
        "\n",
        "    results = []\n",
        "    for window_end in range(lookback_window_length + 1, len(time_series_data)):\n",
        "        ts_data_window = time_series_data.iloc[\n",
        "            window_end - (lookback_window_length + 1) : window_end\n",
        "        ][[\"Date\", \"daily_return\"]].copy()\n",
        "        ts_data_window[\"X\"] = ts_data_window.index.astype(float)\n",
        "        ts_data_window = ts_data_window.rename(columns={\"daily_return\": \"Y\"})\n",
        "        time_index = window_end - 1\n",
        "        window_date = ts_data_window[\"Date\"].iloc[-1].strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        if use_kM_hyp_to_initialize_kC:\n",
        "            cp_score, cp_loc, cp_loc_normalised, _, _ = changepoint_loc_and_score(ts_data_window)\n",
        "        else:\n",
        "            cp_score, cp_loc, cp_loc_normalised, _, _ = changepoint_loc_and_score(\n",
        "                    ts_data_window,\n",
        "                    k1_lengthscale=1.0,\n",
        "                    k1_variance=1.0,\n",
        "                    k2_lengthscale=1.0,\n",
        "                    k2_variance=1.0,\n",
        "                    kC_likelihood_variance=1.0,\n",
        "                )\n",
        "        # results.append([window_date, time_index, cp_loc, cp_loc_normalised, cp_score])\n",
        "        results.append([window_date, cp_loc_normalised, cp_score])\n",
        "    #results_df = pd.DataFrame(results, columns=[\"date\", \"t\", \"cp_location\", \"cp_location_norm\", \"cp_score\"])\n",
        "    results_df = pd.DataFrame(results, columns = ['date', 'cp_location_norm', 'cp_score'])\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TwNL-8377MzK"
      },
      "outputs": [],
      "source": [
        "lookback_window_length = 21\n",
        "start_date = dt.datetime(2017, 12, 31)\n",
        "end_date = dt.datetime(2025, 5, 25)\n",
        "\n",
        "result = run_CPD(\n",
        "    time_series_data=daily_return_df,\n",
        "    # time_series_data   = df_returns,\n",
        "    lookback_window_length=lookback_window_length,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    use_kM_hyp_to_initialize_kC=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ek9H4nPsMKDK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>cp_location_norm</th>\n",
              "      <th>cp_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>0.535089</td>\n",
              "      <td>0.648772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-02</td>\n",
              "      <td>0.667476</td>\n",
              "      <td>0.650288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-05</td>\n",
              "      <td>0.517382</td>\n",
              "      <td>0.649128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-06</td>\n",
              "      <td>0.653670</td>\n",
              "      <td>0.633856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-07</td>\n",
              "      <td>0.112936</td>\n",
              "      <td>0.988312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1815</th>\n",
              "      <td>2025-05-16</td>\n",
              "      <td>0.404285</td>\n",
              "      <td>0.831232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>2025-05-19</td>\n",
              "      <td>0.513865</td>\n",
              "      <td>0.860893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>2025-05-20</td>\n",
              "      <td>0.620829</td>\n",
              "      <td>0.747728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>0.668478</td>\n",
              "      <td>0.800450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>2025-05-22</td>\n",
              "      <td>0.720537</td>\n",
              "      <td>0.849953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1820 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  cp_location_norm  cp_score\n",
              "0     2018-02-01          0.535089  0.648772\n",
              "1     2018-02-02          0.667476  0.650288\n",
              "2     2018-02-05          0.517382  0.649128\n",
              "3     2018-02-06          0.653670  0.633856\n",
              "4     2018-02-07          0.112936  0.988312\n",
              "...          ...               ...       ...\n",
              "1815  2025-05-16          0.404285  0.831232\n",
              "1816  2025-05-19          0.513865  0.860893\n",
              "1817  2025-05-20          0.620829  0.747728\n",
              "1818  2025-05-21          0.668478  0.800450\n",
              "1819  2025-05-22          0.720537  0.849953\n",
              "\n",
              "[1820 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
